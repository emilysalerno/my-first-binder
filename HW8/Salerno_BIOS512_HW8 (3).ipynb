{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"77b97eda-a875-49d9-922a-aca98f18d1ea","cell_type":"markdown","source":"# Homework 08\nThis homework is based on the clustering lectures. Check the lecture notes and TA notes - they should help!","metadata":{}},{"id":"f75ac688-c3c4-4916-a858-97104be7e273","cell_type":"markdown","source":"## Question 1\nThis question will walk you through creating your own `kmeans` function.","metadata":{}},{"id":"9eb3eefd-fd8c-4688-8b9e-e2368e56d526","cell_type":"markdown","source":"#### a) What are the steps of `kmeans`?\n**Hint**: There are 4 steps/builder functions that you'll need.","metadata":{}},{"id":"77b4faa8-a6b3-4adf-b775-8c5cd3eeeade","cell_type":"code","source":"library(dplyr)","metadata":{"trusted":false},"outputs":[{"name":"stderr","output_type":"stream","text":"\nAttaching package: ‘dplyr’\n\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\n\n\nThe following objects are masked from ‘package:base’:\n\n    intersect, setdiff, setequal, union\n\n\n"}],"execution_count":1},{"id":"42250124-039d-4ee5-97f4-f7c77888e52d","cell_type":"code","source":"#a \n#1) Randomly assign points to clusters. 2) Compute cluster means. 3) Reassign points to the nearest centroid. 4) Recompute centroids.","metadata":{"trusted":false},"outputs":[],"execution_count":2},{"id":"bf8b199b-d1d9-4a55-ad95-9e86ad0655bd","cell_type":"markdown","source":"#### b) Create the builder function for step 1.","metadata":{}},{"id":"83782025-5ce3-4cbb-b7c8-0142a22b42a2","cell_type":"code","source":"#b\nlabel_randomly <- function(n_points, n_clusters){\n    sample(((1:n_points) %% n_clusters)+1, n_points, replace=F) #%% gives the remainder of points/clusters\n}","metadata":{"trusted":false},"outputs":[],"execution_count":3},{"id":"9e44ddaf-4506-47d0-98fb-09871e08808c","cell_type":"markdown","source":"#### c) Create the builder function for step 2.","metadata":{}},{"id":"3ca432a3-5e7f-4420-9447-2d69cfd30ca0","cell_type":"code","source":"#c \nget_cluster_means <- function(data, labels){\n    data %>% \n      mutate(label__ = labels) %>% \n      group_by(label__) %>%\n      summarize(across(where(is.numeric), mean)) %>%\n      ungroup()\n}","metadata":{"trusted":false},"outputs":[],"execution_count":4},{"id":"1c8640c6-2d2f-49c3-b7ed-da0d4fb13935","cell_type":"markdown","source":"#### d) Create the builder function for step 3.\n*Hint*: There are two ways to do this part - one is significantly more efficient than the other. You can do either.  ","metadata":{}},{"id":"f4c319e4-6caa-40c1-b5ff-71796129416c","cell_type":"code","source":"assign_cluster <- function(data, means) {\n  data_num <- as.matrix(data %>% select(where(is.numeric)))\n  means_num <- as.matrix(means %>% select(where(is.numeric), -label__))\n  n_points <- nrow(data_num)\n  n_clusters <- nrow(means_num)\n  labels <- numeric(n_points)\n  \n  for (i in 1:n_points) {\n    point <- data_num[i, ]\n    dists <- colSums((t(means_num) - point)^2) # vectorized over clusters\n    labels[i] <- means$label__[which.min(dists)]\n  }\n  labels\n}","metadata":{"trusted":false},"outputs":[],"execution_count":5},{"id":"2bbea660-9bd2-4dae-9a5c-838f613b0d7c","cell_type":"markdown","source":"#### e) Create the builder function for step 4.","metadata":{}},{"id":"3642d324-393e-429d-a32a-66b356ff20b1","cell_type":"code","source":"#e\nkmeans_done <- function(old_means, new_means, eps=1e-6){\n    om <- as.matrix(old_means %>% select(where(is.numeric))) \n \n   nm <- as.matrix(new_means %>% select(where(is.numeric)))\n    \n    om <- om[order(old_means$label__), ]\n    nm <- nm[order(new_means$label__), ]\n    \n    m <- mean(sqrt(rowSums((om - nm)^2)))\n    return(m < eps)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f3c86f61-68d2-484a-9c9c-db7f35c8e685","cell_type":"markdown","source":"#### f) Combine them all into your own `kmeans` function.","metadata":{}},{"id":"55522aab-be01-47a6-b244-54758229f083","cell_type":"code","source":"#f \nmykmeans <- function(data, n_clusters, eps=1e-6){\n    labels <- label_randomly(nrow(data), n_clusters)\n    old_means <- get_cluster_means(data, labels)\n    done <- FALSE\n    while (!done){\n        labels <- assign_cluster(data, old_means)\n        new_means <- get_cluster_means(data, labels)\n        if (kmeans_done(old_means, new_means)){\n            done <- TRUE\n        } else {\n            old_means <- new_means\n        }\n    }\n    \n    list(labels=labels, means=new_means)\n}","metadata":{"trusted":false},"outputs":[],"execution_count":11},{"id":"da13180d-3a51-4218-94a0-3f362612f099","cell_type":"markdown","source":"## Question 2\nThis is when we'll test your `kmeans` function.\n#### a) Read in the `voltages_df.csv` data set. ","metadata":{}},{"id":"2a04dca9-f6a2-44b7-a885-527f17744513","cell_type":"code","source":"#a \nvoltage <- read.csv(\"voltages_df.csv\")","metadata":{"trusted":false},"outputs":[],"execution_count":12},{"id":"1f002a7b-eda1-4d2d-8ef9-3090b563708d","cell_type":"markdown","source":"#### b) Call your `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$means`. ","metadata":{}},{"id":"fc34e677-fa90-41c3-b3d3-09d52c95faa3","cell_type":"code","source":"#b\nresults <- mykmeans(voltage, n_clusters = 3)\nprint(results$labels)\nprint(results$means)","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"  [1] 3 3 3 3 3 3 1 2 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 2 1 1 3 2 1 3 3\n [38] 3 1 3 3 3 3 2 3 2 2 3 2 2 3 1 3 3 1 3 3 3 1 3 3 3 3 3 2 2 3 1 3 2 3 3 1 1\n [75] 3 3 3 1 1 1 1 2 3 1 2 3 3 3 3 1 1 1 3 2 3 3 2 3 3 2 1 2 3 2 3 3 1 3 3 3 3\n[112] 3 3 1 3 2 3 3 3 3 3 3 3 3 2 3 3 1 3 1 3 3 3 1 3 3 3 3 3 2 3 3 3 1 3 3 3 3\n[149] 3 2 3 2 3 3 2 3 1 2 3 3 1 1 3 3 3 1 3 3 3 3 3 2 3 3 1 2 3 1 3 3 1 3 1 3 1\n[186] 3 3 3 3 3 3 3 3 3 2 1 3 3 3 3 2 3 1 2 3 3 3 2 3 3 3 2 3 1 1 3 1 2 3 3 3 3\n[223] 3 3 3 1 1 2 2 3 3 3 2 3 3 2 2 3 3 1 1 3 2 2 3 1 3 1 1 3 2 3 3 2 3 1 1 3 3\n[260] 3 3 3 1 3 3 3 3 1 1 1 3 3 3 3 2 3 1 2 3 3 1 3 2 3 3 3 2 3 3 1 2 3 1 2 3 3\n[297] 3 1 1 3 3 1 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 1 3 3 3 3 3 3 3 3 1\n[334] 3 3 3 2 2 3 3 2 3 2 1 3 1 3 2 3 3 1 3 3 3 3 1 3 3 2 2 3 3 3 3 3 1 3 3 3 3\n[371] 3 3 3 3 3 2 2 3 3 3 3 1 1 3 3 2 2 3 3 1 3 3 3 3 3 1 3 3 2 3 3 3 3 3 3 3 3\n[408] 1 1 1 3 2 2 3 3 3 3 1 3 3 3 3 3 3 3 2 3 3 3 3 1 2 3 2 3 3 3 3 3 1 2 2 1 3\n[445] 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 1 3 3 3 1 3 3 3 3 1 2 3 2 3 3 3 2 3 2 3 3 3\n[482] 2 3 1 1 1 3 2 1 1 1 1 3 3 3 2 2 3 3 3 3 3 3 3 3 3 1 2 3 1 3 3 3 1 1 3 1 1\n[519] 3 3 3 3 3 2 3 3 2 1 3 3 1 1 2 1 3 3 3 3 3 3 3 3 3 1 3 3 2 3 3 3 3 3 3 3 1\n[556] 2 3 2 1 1 3 1 2 3 1 1 3 1 2 3 1 3 1 3 2 3 3 3 3 1 1 1 2 3 3 1 1 2 3 1 2 3\n[593] 3 3 2 3 3 3 3 3 2 3 3 1 3 3 1 1 1 3 1 3 3 3 2 3 3 3 3 3 2 3 3 2 1 3 3 3 1\n[630] 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 1 1 3 2 3 1 3 2 3 3 3 3 3 3 3 3 3 3 3\n[667] 3 3 2 1 3 3 3 3 3 1 3 3 3 2 3 3 2 1 3 3 3 3 3 3 2 1 2 2 3 3 3 3 2 3 3 2 2\n[704] 3 3 1 3 1 1 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3\n[741] 3 3 1 3 3 3 3 3 1 3 3 3 3 2 3 3 1 3 1 1 3 3 3 1 3 3 1 3 3 3 1 3 2 3 3 3 3\n[778] 2 3 1 3 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 2 3 3 3 3 3 1 1 3\n[815] 1 3 3 3 3 1 3 3 3 3 3 1 1 3 1 1 1 2 2 1 3 3 3 3 1 2 3 3 2 1 1 1 3 3 3 1 3\n[852] 3 1 1 1 2 3 3 1 1 1 2 1 3 3 1 3 3 3 3 2 3 1 1 3 3 3 3 3 3 2 3 2 3 3 3 3 1\n[889] 2 3 3 1 1 3 3 3 3 3 2 2\n\u001b[90m# A tibble: 3 × 251\u001b[39m\n  label__    X0 X1.00401606425703 X2.00803212851406 X3.01204819277108\n    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n\u001b[90m1\u001b[39m       1 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m              1.31             1.16              0.977\n\u001b[90m2\u001b[39m       2 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m              1.31             1.16              0.982\n\u001b[90m3\u001b[39m       3 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m              1.09             0.927             0.632\n\u001b[90m# ℹ 246 more variables: X4.01606425702811 <dbl>, X5.02008032128514 <dbl>,\u001b[39m\n\u001b[90m#   X6.02409638554217 <dbl>, X7.0281124497992 <dbl>, X8.03212851405623 <dbl>,\u001b[39m\n\u001b[90m#   X9.03614457831325 <dbl>, X10.0401606425703 <dbl>, X11.0441767068273 <dbl>,\u001b[39m\n\u001b[90m#   X12.0481927710843 <dbl>, X13.0522088353414 <dbl>, X14.0562248995984 <dbl>,\u001b[39m\n\u001b[90m#   X15.0602409638554 <dbl>, X16.0642570281125 <dbl>, X17.0682730923695 <dbl>,\u001b[39m\n\u001b[90m#   X18.0722891566265 <dbl>, X19.0763052208835 <dbl>, X20.0803212851406 <dbl>,\u001b[39m\n\u001b[90m#   X21.0843373493976 <dbl>, X22.0883534136546 <dbl>, …\u001b[39m\n"}],"execution_count":13},{"id":"03d9949c-60ce-4a75-8688-e3c7485122ab","cell_type":"markdown","source":"#### c) Call R's `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$cluster`. \n*Hint*: Use the `as.matrix()` function to make the `voltages_df` data frame a matrix before calling `kmeans()`.","metadata":{}},{"id":"b08adcf0-c30c-43a9-9679-76a4b22f736e","cell_type":"code","source":"#c\nvoltages_matrix <- as.matrix(voltage %>% select(where(is.numeric)))\nresults <- kmeans(voltages_matrix, centers = 3)\nprint(results$cluster)\nprint(results$centers)","metadata":{"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"  [1] 1 3 3 3 3 3 2 2 3 1 1 1 2 1 3 1 1 1 1 1 3 3 3 3 3 1 1 1 2 2 2 2 3 2 2 3 3\n [38] 1 2 3 1 1 1 2 3 2 2 3 2 2 3 2 1 1 2 1 3 1 2 3 1 1 3 1 2 2 3 2 1 2 1 3 2 2\n [75] 3 3 1 2 2 2 2 2 3 2 2 3 3 3 1 2 2 2 3 2 3 3 2 3 3 2 2 2 3 2 1 1 2 1 1 3 1\n[112] 1 3 2 1 2 1 1 3 3 3 3 1 1 2 3 3 2 1 2 3 1 3 2 1 3 3 3 1 2 1 3 3 2 1 1 3 1\n[149] 1 2 1 2 3 3 2 1 2 2 3 1 2 2 1 3 1 2 3 1 3 1 1 2 3 1 2 2 3 2 1 3 2 3 2 1 2\n[186] 3 3 1 3 1 1 3 1 1 2 2 1 3 1 1 2 1 2 2 3 1 3 2 3 1 3 2 1 2 2 3 2 2 3 3 3 3\n[223] 3 3 3 2 2 2 2 1 3 1 2 3 3 2 2 1 1 2 2 1 2 2 3 2 1 2 2 3 2 3 1 2 3 2 2 1 1\n[260] 1 3 3 2 1 3 3 3 2 2 2 1 3 3 3 2 1 2 2 3 3 2 1 2 1 1 3 2 3 3 2 2 1 2 2 1 3\n[297] 1 2 2 3 3 2 1 1 1 2 1 3 3 3 1 1 1 1 1 1 3 1 3 1 1 2 3 2 1 1 1 1 3 1 3 1 2\n[334] 1 3 3 2 2 1 3 2 3 2 2 1 2 3 2 1 1 2 3 3 3 1 2 3 1 2 2 3 3 3 3 1 2 1 3 1 1\n[371] 1 1 1 3 3 2 2 1 1 1 1 2 2 1 1 2 2 3 3 2 1 3 3 3 3 2 3 3 2 1 1 1 1 3 3 1 1\n[408] 2 2 2 3 2 2 1 3 3 3 2 3 3 3 1 1 3 1 2 3 3 3 3 2 2 3 2 1 3 1 1 1 2 2 2 2 1\n[445] 3 1 1 1 2 3 1 1 1 3 3 1 3 3 1 2 3 3 1 2 3 3 3 1 2 2 1 2 1 3 3 2 1 2 1 3 3\n[482] 2 1 2 2 2 3 2 2 2 2 2 3 1 1 2 2 1 3 3 3 1 1 1 3 3 2 2 1 2 1 3 3 2 2 1 2 2\n[519] 3 1 1 1 3 2 1 3 2 2 1 3 2 2 2 2 1 1 3 1 1 3 3 3 3 2 1 1 2 1 1 1 3 3 1 3 2\n[556] 2 3 2 2 2 3 2 2 3 2 2 3 2 2 1 2 3 2 3 2 3 3 3 1 2 2 2 2 1 3 2 2 2 3 2 2 3\n[593] 3 3 2 1 3 3 1 3 2 3 3 2 1 1 2 2 2 3 2 1 3 1 2 3 1 3 3 1 2 3 1 2 2 1 3 1 2\n[630] 3 1 2 1 3 3 1 3 1 1 1 1 1 3 3 1 2 1 2 2 1 2 3 2 1 2 1 1 1 3 1 1 3 3 1 1 3\n[667] 1 3 2 2 3 1 3 1 1 2 3 3 1 2 1 3 2 2 1 1 3 1 3 3 2 2 2 2 3 3 3 1 2 3 1 2 2\n[704] 1 1 2 3 2 2 1 3 1 2 3 1 3 3 1 3 3 1 1 3 3 1 3 2 1 1 1 1 1 3 3 1 1 3 3 1 3\n[741] 1 3 2 1 1 1 3 1 2 3 3 1 1 2 1 1 2 1 2 2 1 1 3 2 1 3 2 3 3 1 2 3 2 1 3 1 1\n[778] 2 1 2 3 1 1 3 2 3 1 3 1 2 1 1 3 3 3 1 3 1 2 3 3 3 3 1 1 2 3 1 1 1 1 2 2 1\n[815] 2 1 3 1 3 2 3 3 3 3 3 2 2 3 2 2 2 2 2 2 3 1 1 3 2 2 1 3 2 2 2 2 1 1 3 2 3\n[852] 1 2 2 2 2 1 1 2 2 2 2 2 1 3 2 3 1 3 3 2 1 2 2 1 1 3 1 1 1 2 3 2 3 3 1 1 2\n[889] 2 3 1 2 2 3 3 3 3 1 2 2\n         X0 X1.00401606425703 X2.00803212851406 X3.01204819277108\n1 -1.031463         0.9381238         0.7619864         0.3631543\n2 -1.031463         1.3093239         1.1616772         0.9787498\n3 -1.031463         1.2439759         1.0924697         0.9004440\n  X4.01606425702811 X5.02008032128514 X6.02409638554217 X7.0281124497992\n1        -1.1179412         -1.051145        -0.9766807       -0.8694758\n2         0.6481497         -1.168610        -1.1196122       -1.0590962\n3         0.3011754         -1.159714        -1.1098127       -1.0685484\n  X8.03212851405623 X9.03614457831325 X10.0401606425703 X11.0441767068273\n1        -0.6892375        -0.5661321        -0.2497152         0.6027358\n2        -0.9943176        -0.9237437        -0.8457536        -0.7572129\n3        -1.0338649        -1.0022396        -0.9699741        -0.9343697\n  X12.0481927710843 X13.0522088353414 X14.0562248995984 X15.0602409638554\n1         0.6960355         0.3917273        -0.9473202        -1.0883844\n2        -0.6201221        -0.1849969         0.5921819         0.6827391\n3        -0.8943605        -0.8507035        -0.8060072        -0.7647395\n  X16.0642570281125 X17.0682730923695 X18.0722891566265 X19.0763052208835\n1        -1.0443762        -1.0057512        -0.9698542        -0.9344880\n2         0.1509102        -0.8453464        -1.0161305        -0.9911278\n3        -0.7329406        -0.7162848        -0.7155110        -0.7229214\n  X20.0803212851406 X21.0843373493976 X22.0883534136546 X23.0923694779116\n1        -0.8979255        -0.8583498        -0.8130091        -0.7569233\n2        -0.9534526        -0.9278338        -0.9128185        -0.9036753\n3        -0.7325077        -0.7420098        -0.7501943        -0.7564416\n  X24.0963855421687 X25.1004016064257 X26.1044176706827 X27.1084337349398\n1        -0.6702728        -0.3675540         0.5506211         0.9011507\n2        -0.8938970        -0.8772257        -0.8486353        -0.8039844\n3        -0.7604952        -0.7624458        -0.7628025        -0.7623710\n  X28.1124497991968 X29.1164658634538 X30.1204819277108 X31.1244979919679\n1         0.6795731        -0.3524483       -1.04171502        -1.0459201\n2        -0.7376698        -0.6036243        0.06859829         0.8128548\n3        -0.7617723        -0.7607406       -0.75765775        -0.7496843\n  X32.1285140562249 X33.1325301204819 X34.136546184739 X35.140562248996\n1        -0.9892448        -0.9443322       -0.9096994       -0.8815063\n2         0.8645315         0.3007530       -0.8509538       -1.0593609\n3        -0.7333197        -0.7046809       -0.6531653       -0.4914149\n  X36.144578313253 X37.1485943775101 X38.1526104417671 X39.1566265060241\n1      -0.85520281        -0.8276580        -0.7988569       -0.77307667\n2      -0.99733097        -0.9264019        -0.8615397       -0.80559654\n3      -0.01286284         0.4111138         0.4708061       -0.08318854\n  X40.1606425702811 X41.1646586345382 X42.1686746987952 X43.1726907630522\n1        -0.7587053        -0.7632138        -0.7847630        -0.8145071\n2        -0.7625137        -0.7331843        -0.7265177        -0.7332993\n3        -0.6569424        -0.9102454        -0.8994279        -0.7365828\n  X44.1767068273092 X45.1807228915663 X46.1847389558233 X47.1887550200803\n1        -0.8440694        -0.8675246        -0.8809781        -0.8820439\n2        -0.7452244        -0.7541076        -0.7630892        -0.7738323\n3        -0.6090580        -0.4429131        -0.1988909         0.3264548\n  X48.1927710843374 X49.1967871485944 X50.2008032128514 X51.2048192771084\n1        -0.8695599        -0.8435323        -0.8053154        -0.7581727\n2        -0.7890510        -0.8105414        -0.8376561        -0.8674783\n3         0.4558868         0.1505446        -0.5861572        -0.9231358\n  X52.2088353413655 X53.2128514056225 X54.2168674698795 X55.2208835341365\n1        -0.7076670        -0.6518253        -0.6418336        -0.6683513\n2        -0.8961943        -0.9203792        -0.9376461        -0.9467293\n3        -1.0150048        -0.9812155        -0.9519898        -0.9255601\n  X56.2248995983936 X57.2289156626506 X58.2329317269076 X59.2369477911647\n1        -0.7186505        -0.7510866        -0.7687534        -0.7789676\n2        -0.9471597        -0.9387284        -0.9209543        -0.8927547\n3        -0.8963167        -0.8594356        -0.8113235        -0.7465117\n  X60.2409638554217 X61.2449799196787 X62.2489959839357 X63.2530120481928\n1        -0.7875447        -0.7974017        -0.8105436        -0.8270493\n2        -0.8524303        -0.7977063        -0.7247251        -0.5933942\n3        -0.6458075        -0.4698973        -0.2004182        -0.2769707\n  X64.2570281124498 X65.2610441767068 X66.2650602409639 X67.2690763052209\n1       -0.84511879        -0.8619288        -0.8745335        -0.8804324\n2       -0.02666874         0.4729405         0.4144252        -0.4315513\n3       -0.58780082        -0.8843039        -0.9061849        -0.9151609\n  X68.2730923694779 X69.2771084337349 X70.281124497992 X71.285140562249\n1        -0.8778206        -0.8656564       -0.8436347       -0.8120791\n2        -1.0008879        -1.0090643       -0.9817530       -0.9556980\n3        -0.9136858        -0.8979656       -0.8643462       -0.8085071\n  X72.289156626506 X73.2931726907631 X74.2971887550201 X75.3012048192771\n1       -0.7717843        -0.7224965        -0.6589461        -0.5355189\n2       -0.9281157        -0.8958956        -0.8562554        -0.8077624\n3       -0.7200554        -0.3865882         0.5166925         0.8451196\n  X76.3052208835341 X77.3092369477912 X78.3132530120482 X79.3172690763052\n1        -0.4204487        -0.4492026        -0.6247444        -0.7674160\n2        -0.7520997        -0.6983205        -0.6636690        -0.6749499\n3         0.6232395        -0.5961787        -1.0623477        -1.0724163\n  X80.3212851405623 X81.3253012048193 X82.3293172690763 X83.3333333333333\n1        -0.8087844        -0.8300087        -0.8472407        -0.8581972\n2        -0.7301447        -0.8166818        -0.8587393        -0.8799611\n3        -1.0356110        -0.9954282        -0.9528213        -0.9064278\n  X84.3373493975904 X85.3413654618474 X86.3453815261044 X87.3493975903614\n1        -0.8615963        -0.8575195        -0.8475783        -0.8346705\n2        -0.8807739        -0.8565428        -0.8006910        -0.6918535\n3        -0.8582115        -0.8140585        -0.7829844        -0.7718335\n  X88.3534136546185 X89.3574297188755 X90.3614457831325 X91.3654618473896\n1       -0.82209589        -0.8120214        -0.8040541        -0.7951620\n2        0.01211907         1.0445785         0.9417920         0.7389057\n3       -0.77702656        -0.7871946        -0.7928432        -0.7890063\n  X92.3694779116466 X93.3734939759036 X94.3775100401606 X95.3815261044177\n1        -0.7810723        -0.7579365        -0.7232338        -0.6641211\n2        -0.7150875        -1.1089291        -1.0556228        -1.0180026\n3        -0.7742481        -0.7499086        -0.7199963        -0.6912508\n  X96.3855421686747 X97.3895582329317 X98.3935742971888 X99.3975903614458\n1        -0.5714035        -0.4183154        -0.3719077         -0.503291\n2        -0.9953800        -0.9809828        -0.9669849         -0.947114\n3        -0.6620338        -0.6573335        -0.6680024         -0.693500\n  X100.401606425703 X101.40562248996 X102.409638554217 X103.413654618474\n1        -0.7008495       -0.7746358        -0.7625038        -0.7285317\n2        -0.9178894       -0.8791665        -0.8349946        -0.7952200\n3        -0.6899649       -0.6756290        -0.6511730        -0.5867081\n  X104.417670682731 X105.421686746988 X106.425702811245 X107.429718875502\n1        -0.6571094        -0.4043544         0.1265605         0.3638254\n2        -0.7756150        -0.7869612        -0.8196682        -0.8572411\n3        -0.4940197        -0.3959773        -0.4019194        -0.4836075\n  X108.433734939759 X109.437751004016 X110.441767068273 X111.44578313253\n1         0.1859342        -0.4285780        -0.7651785       -0.9118234\n2        -0.8888497        -0.9084385        -0.9129518       -0.9016455\n3        -0.6031085        -0.6803393        -0.7009213       -0.7220232\n  X112.449799196787 X113.453815261044 X114.457831325301 X115.461847389558\n1        -0.9492127        -0.9263633        -0.9037028        -0.8843812\n2        -0.8760331        -0.8402975        -0.8021679        -0.7735978\n3        -0.7586346        -0.7931128        -0.8129309        -0.8240816\n  X116.465863453815 X117.469879518072 X118.473895582329 X119.477911646586\n1        -0.8642445        -0.8387891        -0.8041192        -0.7572864\n2        -0.7672098        -0.7838746        -0.8118719        -0.8402008\n3        -0.8223207        -0.8048594        -0.7706219        -0.7204532\n  X120.481927710843 X121.4859437751 X122.489959839357 X123.493975903614\n1        -0.6936271      -0.5608583        -0.1942616         0.1086731\n2        -0.8622569      -0.8743578        -0.8745548        -0.8621162\n3        -0.6522148      -0.4767159        -0.4081569        -0.5063971\n  X124.497991967871 X125.502008032129 X126.506024096386 X127.510040160643\n1        0.02132084        -0.5326843        -0.8758425        -0.9333571\n2       -0.83738609        -0.8019045        -0.7588503        -0.7139745\n3       -0.76474266        -0.8404665        -0.8547187        -0.8574783\n  X128.5140562249 X129.518072289157 X130.522088353414 X131.526104417671\n1      -0.9340874        -0.9361184        -0.9390643        -0.9391331\n2      -0.6607540        -0.6276292        -0.6446482        -0.7145974\n3      -0.8470736        -0.8237992        -0.7907006        -0.7549813\n  X132.530120481928 X133.534136546185 X134.538152610442 X135.542168674699\n1        -0.9326577        -0.9172195        -0.8925731        -0.8614265\n2        -0.7611321        -0.7857777        -0.8012031        -0.8125440\n3        -0.7297735        -0.7298815        -0.7529255        -0.7848950\n  X136.546184738956 X137.550200803213 X138.55421686747 X139.558232931727\n1        -0.8300492        -0.8077430       -0.8024823        -0.8136626\n2        -0.8201603        -0.8247583       -0.8271200        -0.8278544\n3        -0.8165587        -0.8425382       -0.8596402        -0.8659917\n  X140.562248995984 X141.566265060241 X142.570281124498 X143.574297188755\n1        -0.8322854        -0.8483442        -0.8544481        -0.8456450\n2        -0.8272444        -0.8252812        -0.8218972        -0.8172887\n3        -0.8606862        -0.8437425        -0.8162919        -0.7810048\n  X144.578313253012 X145.582329317269 X146.586345381526 X147.590361445783\n1        -0.8186060        -0.7708364        -0.6983153        -0.4995888\n2        -0.8121326        -0.8075060        -0.8044394        -0.8032921\n3        -0.7418578        -0.7067689        -0.6901358        -0.7059361\n  X148.59437751004 X149.598393574297 X150.602409638554 X151.606425702811\n1       0.06111762         0.2785784       -0.02233891        -0.8344614\n2      -0.80337598        -0.8031237       -0.80065690        -0.7943595\n3      -0.73487063        -0.7666850       -0.79030791        -0.8088526\n  X152.610441767068 X153.614457831325 X154.618473895582 X155.622489959839\n1        -1.0044925        -0.9947944        -0.9812626        -0.9611036\n2        -0.7832322        -0.7670602        -0.7465418        -0.7235183\n3        -0.8202897        -0.8228722        -0.8145883        -0.7924833\n  X156.626506024096 X157.630522088353 X158.63453815261 X159.638554216867\n1        -0.9329663        -0.8974015       -0.8567861        -0.8149502\n2        -0.7012304        -0.6807904       -0.6728119        -0.6832253\n3        -0.7512216        -0.6757423       -0.3063965         0.8688481\n  X160.642570281125 X161.646586345382 X162.650602409639 X163.654618473896\n1        -0.7765148        -0.7457931       -0.72540822        -0.7155786\n2        -0.7054310        -0.7309402       -0.75082774        -0.7686511\n3         0.9679233         0.7772804       -0.07183464        -1.1062019\n  X164.658634538153 X165.66265060241 X166.666666666667 X167.670682730924\n1        -0.7153215       -0.7238374        -0.7399730        -0.7613774\n2        -0.7816786       -0.7870605        -0.7817687        -0.7624390\n3        -1.0341477       -0.9682607        -0.9201250        -0.8912380\n  X168.674698795181 X169.678714859438 X170.682730923695 X171.686746987952\n1        -0.7843319        -0.8048796        -0.8195663        -0.8257305\n2        -0.7245206        -0.6548498        -0.3204002         0.6097598\n3        -0.8785268        -0.8757421        -0.8765711        -0.8763897\n  X172.690763052209 X173.694779116466 X174.698795180723 X175.70281124498\n1        -0.8215405        -0.8059275        -0.7785542       -0.7399101\n2         0.9159961         0.6867779        -0.3890717       -1.0366319\n3        -0.8723257        -0.8627871        -0.8471194       -0.8255329\n  X176.706827309237 X177.710843373494 X178.714859437751 X179.718875502008\n1        -0.6905890        -0.5947843        -0.4888176        -0.4608156\n2        -1.0173625        -0.9442263        -0.8744008        -0.8208368\n3        -0.7992863        -0.7711209        -0.7458106        -0.7301849\n  X180.722891566265 X181.726907630522 X182.730923694779 X183.734939759036\n1        -0.5897696        -0.7499744        -0.8130170        -0.8299556\n2        -0.7929042        -0.7922503        -0.8086421        -0.8305061\n3        -0.7295152        -0.7412643        -0.7592950        -0.7779570\n  X184.738955823293 X185.74297188755 X186.746987951807 X187.751004016064\n1        -0.8409305       -0.8452711        -0.8433730        -0.8365057\n2        -0.8505003       -0.8644851        -0.8698348        -0.8643891\n3        -0.7932478       -0.8027234        -0.8053583        -0.8015959\n  X188.755020080321 X189.759036144578 X190.763052208835 X191.767068273092\n1        -0.8265279        -0.8155633        -0.8057013        -0.7987310\n2        -0.8458421        -0.8111387        -0.7548184        -0.6525374\n3        -0.7935596        -0.7852354        -0.7820492        -0.7889309\n  X192.771084337349 X193.775100401606 X194.779116465863 X195.78313253012\n1        -0.7958760        -0.7975586        -0.8033236       -0.8120201\n2        -0.1001499         0.9391002         0.9285660        0.6517322\n3        -0.8074163        -0.8348509        -0.8664015       -0.8970687\n  X196.787148594378 X197.791164658635 X198.795180722892 X199.799196787149\n1        -0.8221502        -0.8321654        -0.8405697        -0.8458446\n2        -0.7358678        -1.0895200        -1.0154215        -0.9519020\n3        -0.9225360        -0.9394094        -0.9452854        -0.9387656\n  X200.803212851406 X201.807228915663 X202.81124497992 X203.815261044177\n1        -0.8463236        -0.8401411       -0.8253304        -0.8000397\n2        -0.9026096        -0.8696398       -0.8523352        -0.8471801\n3        -0.9194256        -0.8877457       -0.8449963        -0.7930944\n  X204.819277108434 X205.823293172691 X206.827309236948 X207.831325301205\n1        -0.7627423        -0.7118802        -0.6216330        -0.4156647\n2        -0.8494938        -0.8551073        -0.8607785        -0.8638455\n3        -0.7343536        -0.6691135        -0.4838896        -0.2999128\n  X208.835341365462 X209.839357429719 X210.843373493976 X211.847389558233\n1        -0.0534988        0.02474902        -0.2568694        -0.7093632\n2        -0.8618848       -0.85264306        -0.8342272        -0.8054928\n3        -0.1804235       -0.35598898        -0.5162496        -0.2364068\n  X212.85140562249 X213.855421686747 X214.859437751004 X215.863453815261\n1       -0.8470668        -0.8120225        -0.7573180        -0.6723234\n2       -0.7666557        -0.7200529        -0.6620238        -0.6140577\n3        0.3284619         0.3395453         0.1645395        -0.2989640\n  X216.867469879518 X217.871485943775 X218.875502008032 X219.879518072289\n1        -0.6164225        -0.5988228        -0.6411442        -0.6640895\n2        -0.6263134        -0.6911566        -0.7582236        -0.7853809\n3        -0.4018100        -0.3585309        -0.3290437        -0.5004164\n  X220.883534136546 X221.887550200803 X222.89156626506 X223.895582329317\n1        -0.6739551        -0.6798595       -0.6872401        -0.7007792\n2        -0.7957568        -0.7917830       -0.7707133        -0.7296389\n3        -0.4362260        -0.3927307       -0.6306939        -0.9151246\n  X224.899598393574 X225.903614457831 X226.907630522088 X227.911646586345\n1        -0.7162648        -0.7369719        -0.7604956        -0.7832985\n2        -0.6592842        -0.3841880         0.3496670         0.6369398\n3        -0.9574830        -0.9648791        -0.9703784        -0.9712805\n  X228.915662650602 X229.919678714859 X230.923694779116 X231.927710843374\n1        -0.8022765        -0.8152619        -0.8211078        -0.8195989\n2         0.3579089        -0.6477129        -1.0293754        -1.0263127\n3        -0.9661478        -0.9552204        -0.9406667        -0.9264022\n  X232.931726907631 X233.935742971888 X234.939759036145 X235.943775100402\n1        -0.8113355        -0.7976862        -0.7808822        -0.7642316\n2        -0.9953023        -0.9687414        -0.9424557        -0.9113858\n3        -0.9170391        -0.9158466        -0.9227888        -0.9344310\n  X236.947791164659 X237.951807228916 X238.955823293173 X239.95983935743\n1        -0.7521010        -0.7487914        -0.7560044       -0.7713512\n2        -0.8701538        -0.8128519        -0.7279844       -0.4718942\n3        -0.9457199        -0.9518850        -0.9493809       -0.9360238\n  X240.963855421687 X241.967871485944 X242.971887550201 X243.975903614458\n1        -0.7900387        -0.8070676        -0.8182598        -0.8207339\n2         0.3364266         0.8337474         0.7125412        -0.2659209\n3        -0.9107472        -0.8732292        -0.8234477        -0.7607812\n  X244.979919678715 X245.983935742972 X246.987951807229 X247.991967871486\n1        -0.8132928        -0.7969549       -0.77567272       -0.75689256\n2        -1.0409179        -1.0587745       -1.01359887       -0.96467777\n3        -0.6682618        -0.3380864       -0.04693168        0.02820486\n  X248.995983935743       X250\n1        -0.7496483 -0.7570393\n2        -0.9151047 -0.8610245\n3        -0.4113500 -0.8115784\n"}],"execution_count":14},{"id":"4944ea46-ed01-413b-8b55-d55f383413de","cell_type":"markdown","source":"#### d) Are your labels/clusters the same? If not, why? Are your means the same?","metadata":{}},{"id":"ad02ef06-8f26-482f-bc8e-d33e68dc5aff","cell_type":"code","source":"#d The labels and clusters are not the same since cluster centers are chosen randomly. The means are similar but not the same. ","metadata":{"trusted":false},"outputs":[],"execution_count":3},{"id":"6228e5ce-269f-4d83-b94e-40f3c4a137cd","cell_type":"markdown","source":"## Question 3\n#### a) Explain the process of using a for loop to assign clusters for kmeans.","metadata":{}},{"id":"918fcb4c-a8b8-4e88-9b93-67090ece10ab","cell_type":"code","source":"#a the loop allows to go through each point of the dataset, monitor the closest cluster found as it works its way through the dataset, check the distance from each point to each cluster center,and assign a point to the closest cluster","metadata":{"trusted":false},"outputs":[],"execution_count":4},{"id":"2815b679-8bd1-4ec2-85d3-e42166f3e0ff","cell_type":"markdown","source":"#### b) Explain the process of vectorizing the code to assign clusters for kmeans.","metadata":{}},{"id":"768cc279-117c-4a7b-9311-dfeff544a68f","cell_type":"code","source":"#b vecotrizing the code makes the kmeans function faster since it avoids the nested for loops. Instead of loop through each data point, the vectorization computes distances for all clusters at once","metadata":{"trusted":false},"outputs":[],"execution_count":5},{"id":"c6be7b85-c4f0-4626-b7f5-0ba921efcb6d","cell_type":"markdown","source":"#### c) State which (for loops or vectorizing) is more efficient and why.","metadata":{}},{"id":"9a32eb3a-9bd4-4571-9e3a-a0aa2fab66cc","cell_type":"code","source":"#c Vectorization is more efficient as it computes distances for all data points to all the clusters at one time instead of finding the distance for one data point before moving on to the next data point.","metadata":{"trusted":false},"outputs":[],"execution_count":6},{"id":"3d2824d8-b8b6-4746-8fdc-8b3a8a1ca49d","cell_type":"markdown","source":"## Question 4\n#### When does `kmeans` fail? What assumption does `kmeans` use that causes it to fail in this situation?","metadata":{}},{"id":"81f0d006-0afe-4df0-a65b-8039b471e31f","cell_type":"code","source":"# kmeans fails when the assumptions are violated. these assumptions include spherical clusters, clusters of similar sizes that don't have a lot of overlap, and numeric and scaled features. In this situation\n# the high dimensionality of the data is likely what caused the kmeans to fail.","metadata":{"trusted":false},"outputs":[],"execution_count":7},{"id":"20c5a711-449c-48e0-b02b-8ad3346e8d38","cell_type":"markdown","source":"## Question 5\n#### What assumption do Guassian mixture models make?","metadata":{}},{"id":"0fb72b6b-8b0f-4327-8d6d-83ecf69b4a54","cell_type":"code","source":"# These models assume that data comes from a mix of mulitple normal distributions whose individual parameters are estimated from the data","metadata":{"trusted":false},"outputs":[],"execution_count":8},{"id":"ed1a4f52-f2d5-45d7-aeb2-a05ccab9e2fe","cell_type":"markdown","source":"## Question 6\n#### What assumption does spectral clustering make? Why does this help us?","metadata":{}},{"id":"996bed88-f253-4d2f-b390-50bbf0092696","cell_type":"code","source":"#Spectral clustering assumes that two points are more likely to be in the same cluster if they are close to one another. This is helpful because it allows us to work with more types of data","metadata":{"trusted":false},"outputs":[],"execution_count":9},{"id":"ede993cf-222f-4c5b-b09e-bc2c988a777e","cell_type":"markdown","source":"## Question 7\n#### Define the gap statistic method. What do we use it for?","metadata":{}},{"id":"bb72438b-437b-4d67-9cfb-ec2e1bc28b25","cell_type":"code","source":"# The gap statistic method compares the clustering for each value of K to a cluster of data \"randomized\" into the same domain as the original data. The dispersion of the two clusterings is then calculated \n# and differences are observed. We look for a \"knee\" and that becomes the cluster number. Its used estimate the number of clusters based on the data.  ","metadata":{"trusted":false},"outputs":[],"execution_count":10}]}